---
layout: post
title: Kafka Tip
excerpt: "개발하며 필요한 Kafka 명렁어나 설정등에 대한 tip 모음"
tags: [tip, queue]
modified: 2020-06-24
comments: true
category : etc
---

{% include _toc.html %}


KAFKA
==============================

### 설치/설정관련


server.properties
- 카프카 서버 설정 ( 클러스터들 주소, 주키퍼 주소 등 )
- broker.id 는 클러스터마다 바꿔줘야 함

zookeeper.properties
- 주키퍼 구동 관련 (포트 등 )

connect-distributed.properties	
- connect 사용시 distribute 모드의 설정 ( 기본 connector 설정 및 cluster groupId 정도, 나머지는 REST API로 connerter마다 설정 )

log4j.properties
- kafka 로그 관련
connect-log4j.properties  


주키퍼 기동
~~~
./bin/zkServer.sh start
./bin/zkServer.sh stop
~~~

카프카 기동
~~~
./bin/kafka-server-start.sh ./config/server.properties
nohup ./bin/kafka-server-start.sh ./config/server.properties &
~~~

카프카 커넥트 기동
~~~
./bin/kafka-server-stop.sh ./config/server.properties
~~~


### CLI 명령

토픽 생성
~~~
./kafka-topics.sh --zookeeper {zookeeper-servers}:2181/{name} --replication-factor 1 --partitions 1 --topic {topic} --create
~~~

토픽에 Publish
~~~
./kafka-console-producer.sh --broker-list {kafka-servers}:9092 --topic {topic}
~~~

토픽을 consuming
~~~
./kafka-console-consumer.sh --bootstrap-server {kafka-servers}:9092 --topic {topic} --from-beginning
~~~


토픽정보 조회
~~~
./kafka-topics.sh —-bootstrap-server {kafka-servers}:9092 —-list
~~~

토픽특성확인
~~~
./kafka-topics.sh --zookeeper  {kafka-servers}:2181/{name} --topic {topic} --describe 
~~~


토픽설정 변경 (retain)
~~~
./kafka-configs.sh --zookeeper {kafka-servers}:2181/{name} --entity-type topics --entity-name {topic} --add-config "retention.ms=3600000" --alter
~~~


토픽설정 확인 (retain)
~~~
./kafka-configs.sh --zookeeper {kafka-servers}:2181/{name} --entity-type topics --entity-name {topic} --describe
~~~

토픽의 replica 재지정 ( rf.json 파일을 만들어서 처리해야 함 )
~~~
./kafka-reassign-partitions.sh --zookeeper {kafka-servers}:2181/{name} --reassignment-json-file ./rf.json --execute

rf.json
{
	"version" : 1,
	"partitions" : [
	  { "topic" : "{topic}"
	    ,"partition" : 0
	    ,"replicas" : [1,2]
	  }
	]
}
~~~



컨슈머 그룹 리스트 조회
~~~
./kafka-consumer-groups.sh --bootstrap-server {kafka-servers}:9092 --all-topics --list
~~~

컨슈머 그룹의 정보조회(offset, LAG 등)
~~~
./kafka-consumer-groups.sh --bootstrap-server {kafka-servers}:9092 --group connect-apache-log-es-sink-render-connector --describe
~~~

컨슈머 그룹의 정보조회(offse 재지정)
~~~
./kafka-consumer-groups.sh --bootstrap-server {kafka-servers}:9092 --group {consumer-group-name} ——topic {topic} —-reset-offsets --to-latest --execute
~~~



// 특정 토픽의 시간조건(time -1, -2, timestamp)의 offset 정보 조회
~~~
./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list aveditorspare01.ugedit.nfra.io:9092 --topic platform-api-apache-logs --time -1
~~~


KAFKA Connect
=============================

### kafka connect distribute REST API 

connector 목록조회
~~~
GET http://{kafka-connect-server}:8083/connectors
~~~

connector 등록
~~~
POST http://{kafka-connect-server}:8083/connectors
~~~

connector 상세내용 조회
~~~
GET http://{kafka-connect-server}:8083/connectors/{connector-name}
~~~

connector 수정
~~~
PUT http://{kafka-connect-server}:8083/connectors/{connector-name}
~~~

connector 삭제
~~~
DELETE http://{kafka-connect-server}:8083/connectors/{connector-name}
~~~


connector 상태조회
~~~
GET http://{kafka-connect-server}:8083/connectors/{connector-name}/status
~~~

0번째 테스크의 상태조회
~~~
GET http://{kafka-connect-server}:8083/connectors/{connector-name}/tasks/0/status
~~~

0번째 테스크 재시작
~~~
PUT http://{kafka-connect-server}:8083/connectors/{connector-name}/tasks/0/restart
~~~

0번째 테스크 정지
~~~
PUT http://{kafka-connect-server}:8083/connectors/{connector-name}/tasks/0/pause
~~~



Schema Registry
===================


### kafka registry 설정

여러 오픈소스가 존재하는 듯하지만
confluent걸 사용 (confluent 풀패키지를 받아야 함… )

압축해제 후 
~~~
./bin/schema-registry-start ./etc/schema-registry/schema-registry.properties
~~~

설정파일 조정
schema-registry.properties

주키퍼를 사용하는 방법이 있는듯하지만, kafka를 직접 이요하는 방법 사용을 위해 아래 부분 설정 ( 9092 카프카 port)
kafkastore.bootstrap.servers=PLAINTEXT://localhost:9092


설정방식 조회 ( backward, forward, all )
~~~
http://localhost:8081/config
~~~

등록된 스키마 조회
~~~
http://localhost:8081/subjects
http://localhost:8081/subjects/{스키마이름}
http://localhost:8081/subjects/{스키마이름}/version/1
~~~

새로운 스키마로 전송할때마다, 버젼이 쌓임.

스키마파일 (id로 찾음)는 kafka에 _schemas 토픽에 담겨져있음.

설전변환
~~~
curl --header "Content-Type: application/json" -X PUT   --data '{"compatibility": "FULL"}'
~~~

설정방식 특징

backward(기본) :  추가 default가 없으면 produce시 에러 , default가 null이 아닌값으로 지정되어야 함 (필드 삭제시는 괜찮음)
                         
forward : 삭제시 default 없으면 에러 produce시 에러 (backward와 반대)

full : 필드추가, 필드삭제 모두 default가 고려 안되면 produce 못함
